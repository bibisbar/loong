{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check out this cookbook in Google Colab [here](https://colab.research.google.com/github/camel-ai/loong/blob/main/cookbooks/collect_synthetic_data.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"align-center\">\n",
    "  <a href=\"https://www.camel-ai.org/\"><img src=\"https://i.postimg.cc/KzQ5rfBC/button.png\"width=\"150\"></a>\n",
    "  <a href=\"https://discord.camel-ai.org\"><img src=\"https://i.postimg.cc/L4wPdG9N/join-2.png\"  width=\"150\"></a></a>\n",
    "  \n",
    "‚≠ê <i>Star us on [*Github*](https://github.com/camel-ai/camel), join our [*Discord*](https://discord.camel-ai.org) or follow our [*X*](https://x.com/camelaiorg)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Install camel if you don't have it\n",
    "!pip install \"git+https://github.com/camel-ai/camel.git#egg=camel-ai[all]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from camel.datasets.static_dataset import StaticDataset\n",
    "from camel.datasets.few_shot_generator import FewShotGenerator\n",
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "from camel.configs import ChatGPTConfig\n",
    "from camel.agents import ChatAgent\n",
    "from camel.extractors import BaseExtractor, BoxedStrategy\n",
    "from camel.verifiers import MathVerifier, PythonVerifier\n",
    "from camel.environments import SingleStepEnv, Action\n",
    "from camel.logger import get_logger, set_log_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(__name__)\n",
    "set_log_level('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enable deepseek reasoning content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GET_REASONING_CONTENT\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = \"math_dataset.json\"\n",
    "ALL_RESPONSES_FILE = \"all_responses.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "    logger.info(f\"Loaded existing dataset with {len(dataset)} examples\")\n",
    "else:\n",
    "    dataset = []\n",
    "    logger.info(\"Starting new dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"camel-ai/loong\", split=\"graph_discrete_math\")\n",
    "\n",
    "seed_dataset = StaticDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Initializing models...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API keys\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "openai_api_key = getpass('Enter your OpenAI API key: ')\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "deepseek_api_key = getpass('Enter your DeepSeek API key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4o = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.OPENAI,\n",
    "    model_type=ModelType.GPT_4O_MINI,\n",
    "    model_config_dict=ChatGPTConfig().as_dict(),\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "model_deepseek = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.DEEPSEEK,\n",
    "    model_type=ModelType.DEEPSEEK_REASONER,\n",
    "    api_key=deepseek_api_key\n",
    ")\n",
    "logger.info(\"Models initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up extractors and verifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Setting up extractors and verifiers...\")\n",
    "extractor = BaseExtractor([[BoxedStrategy()]])\n",
    "await extractor.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_verifier = PythonVerifier(required_packages=[\"sympy\"])\n",
    "await python_verifier.setup(uv=False)\n",
    "\n",
    "math_verifier = MathVerifier(\n",
    "    extractor=extractor,\n",
    "    float_rounding=6,\n",
    "    numeric_precision=15,\n",
    "    enable_wrapping=True\n",
    ")\n",
    "await math_verifier.setup()\n",
    "logger.info(\"Extractors and verifiers setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize generator and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Initializing generator and environment...\")\n",
    "generator = FewShotGenerator(\n",
    "    buffer=10,\n",
    "    seed_dataset=seed_dataset,\n",
    "    verifier=python_verifier,\n",
    "    model=model_4o\n",
    ")\n",
    "\n",
    "env = SingleStepEnv(generator, math_verifier)\n",
    "await env.setup()\n",
    "logger.info(\"Generator and environment initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize agent for CoT generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatAgent(model=model_deepseek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"\"\"You are an agent designed to answer mathematical questions with clarity and precision. Your task is to provide a step-by-step explanation for\n",
    "any mathematical problem posed by the user, ensuring the response is easy to follow. Adhere to these guidelines:\n",
    "Analyze the mathematical question carefully and break down the solution process into clear, logical steps.\n",
    "Use natural language to explain each step, incorporating LaTeX notation (e.g., $x + 2$)\n",
    "for mathematical expressions when helpful. Conclude your response with the final answer enclosed\n",
    "in a LaTeX \\boxed{} environment (e.g., \\boxed{5}).\n",
    "Place this at the end of your explanation as a standalone statement.\n",
    "It should be a Python expression, for example \"[1, 2, 3]\" for a list.\n",
    "\n",
    "The question you should answer is: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation Loop\n",
    "num_rejected = 0\n",
    "target_size = 100\n",
    "\n",
    "logger.info(\"Starting generation and verification loop...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(dataset) < target_size:\n",
    "    logger.info(f\"Current dataset size: {len(dataset)}/{target_size}\")\n",
    "    \n",
    "    obs = await env.reset()\n",
    "    deepseek_response = agent.step(USER_PROMPT + obs.question).msgs[0].content\n",
    "    \n",
    "    # Split the response into reasoning and answer parts\n",
    "    reasoning_part = \"\"\n",
    "    answer_part = deepseek_response\n",
    "    \n",
    "    if \"<think>\" in deepseek_response and \"</think>\" in deepseek_response:\n",
    "        parts = deepseek_response.split(\"</think>\")\n",
    "        if len(parts) > 1:\n",
    "            reasoning_part = parts[0].replace(\"<think>\", \"\").strip()\n",
    "            answer_part = parts[1].strip()\n",
    "    \n",
    "    # Verify through environment\n",
    "    next_obs, reward, done, info = await env.step(Action(index=0, llm_response=deepseek_response))\n",
    "    \n",
    "    # Save all responses\n",
    "    with open(ALL_RESPONSES_FILE, \"a\") as f:\n",
    "        f.write(f\"Question: {obs.question}\\n\")\n",
    "        f.write(f\"Response: {answer_part}\\n\")\n",
    "        f.write(f\"Long CoT: {reasoning_part}\\n\")\n",
    "        f.write(f\"Info: {info}\\n\")\n",
    "        f.write(f\"Verified: {reward > 0}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "    \n",
    "    # Create data entry\n",
    "    data_entry = {\n",
    "        \"question\": obs.question,\n",
    "        \"answer\": info['state'].final_answer if 'state' in info else '',\n",
    "        \"response\": answer_part,\n",
    "        \"long_cot\": reasoning_part,\n",
    "        \"verified\": reward > 0,\n",
    "    }\n",
    "\n",
    "    # Save entry and update dataset\n",
    "    dataset.append(data_entry)\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        json.dump(dataset, f, indent=2)\n",
    "    \n",
    "    if reward > 0:\n",
    "        logger.info(f\"Verification successful - Added verified entry (reward: {reward})\")\n",
    "    else:\n",
    "        num_rejected += 1\n",
    "        logger.warning(f\"Verification failed - Added unverified entry (reward: {reward})\")\n",
    "    \n",
    "    agent.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_entries = len(dataset)\n",
    "verified_entries = sum(1 for entry in dataset if entry[\"verified\"])\n",
    "logger.info(f\"Generation complete. Total entries: {total_entries}\")\n",
    "logger.info(f\"Verified entries: {verified_entries}\")\n",
    "logger.info(f\"Rejected entries: {num_rejected}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
